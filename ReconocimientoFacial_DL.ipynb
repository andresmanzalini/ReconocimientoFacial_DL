{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento Facial con Deep Learning\n",
    "\n",
    "\n",
    "El proyecto consiste en implementar un proyecto para el reconocimiento facial.\n",
    "\n",
    "Para lograrlo, se consideran distintas arquitecturas de redes neuronales para procesamiento de imagenes, junto con el modelo preentrenado dlib , *shape_predictor_68_face_landmarks.dat*\n",
    "\n",
    "Utiliza los modelos preentrenados disponible en Keras VGG16 e Inception. \n",
    "\n",
    "Los mejores resultados los Clasifica con el modelo VGG16 afinado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible hacer reconocimiento facial de un dataset publico o generar un dataset propio.\n",
    "\n",
    "\n",
    "En este caso vamos a generar un dataset personal y hacer reconocimiento facial al grupo familiar.\n",
    "\n",
    "\n",
    "Para personalizar el problema es necesario crear una carpeta que contenga el dataset con las personas y rostros a identificar. \n",
    "\n",
    "Lo hacemos ejecutando la funcion *detectarProcesar_cara.py ID* , usando como parametro la identificacion de la persona.\n",
    "\n",
    "Esta funcion lee las imagenes (del disco o captadas por la camara web) y aplica proprocesamiento. Recorta y alinea la cara, dejando la imagenes listas para entrenar los modelos.\n",
    "\n",
    "\n",
    "Para el correcto funcionamiento es necesaria la libreria DLIB con el modelo preentrenado shape_predictor_68_face_landamarks.dat, disponible en https://github.com/davisking/dlib-models\n",
    "Este modelo fue entrenado con las referencias faciales de muchas personas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imagenes son procesadas por openCV, en blanco y negro para trabajar en una sola dimension de colores.\n",
    "\n",
    "openCV permite recolectar, recortar y alinear las imagenes, mientras que el modelo 68_landmarks.dat identifica los rasgos faciales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '/home/andres/Documentos/IA/Datasets/Caras/Familia/'\n",
    "\n",
    "FORMATO = '.jpg' \n",
    "\n",
    "#DEFAULT_SIZE = (224,224,3) \n",
    "DEFAULT_SIZE = (224,224,1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_cv2 = cv2.__path__[0]+'/data/'\n",
    "haar_type = 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "face_cascada = cv2.CascadeClassifier(data_path_cv2+haar_type)\n",
    "\n",
    "\n",
    "# DLIB\n",
    "path_dlibModel = os.path.dirname(os.getcwd())\n",
    "predictor_model = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "land_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(path_dlibModel+'/'+predictor_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modularizar!\n",
    "\n",
    "cont = 0\n",
    "seguir = True\n",
    "\n",
    "while seguir:\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #sobreescribo formato de salida de GBR a RGB \n",
    "    gris = cv2.cvtColor(frameRGB, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "   \n",
    "    caras_dlib = land_detector(gris,1)\n",
    "\n",
    "    for cara in caras_dlib:\n",
    "        x = cara.left()\n",
    "        y = cara.top()\n",
    "        w = cara.right() - x\n",
    "        h = cara.bottom() - y\n",
    "        \n",
    "        landmarks = predictor(gris, cara)\n",
    "\n",
    "        face_aligned = dlib.get_face_chip(frame, landmarks, DEFAULT_SIZE[0])\n",
    "        \n",
    "        face_aligned_grey = cv2.cvtColor(face_aligned, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        face_aligned_32 = np.asarray(face_aligned, dtype='float32') \n",
    "        im_expand = np.expand_dims(face_aligned_32, axis=0) \n",
    "        im_normalizada = (im_expand - np.min(im_expand)) / (np.max(im_expand) - np.min(im_expand))\n",
    "            \n",
    "        cv2.rectangle(frame, (x,y), (cara.right(),cara.bottom()), (0,255,0), 2)\n",
    "        #cv2.rectangle(face_aligned, (x,y), (cara.right(),cara.bottom()), (0,255,0), 2)\n",
    "        #cv2.rectangle(face_aligned_grey, (x,y), (cara.right(),cara.bottom()), (0,255,0), 2)\n",
    "\n",
    "        \n",
    "        for n in range(0,68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x,y), 2, (255,0,0))\n",
    "            #cv2.circle(face_aligned, (x,y), 2, (255,0,0))\n",
    "            #cv2.circle(face_aligned_grey, (x,y), 2, (255,0,0))\n",
    "        \n",
    "            \n",
    "        if key == ord('s'):\n",
    "            path_nueva_foto = DATASET+ETIQUETA+'/'+ETIQUETA+time.strftime('_%d-%m-%Y_%H-%M-%S')\n",
    "            nombre_foto = ETIQUETA+time.strftime('_%d-%m-%Y_%H-%M-%S')\n",
    "            print(\"Sacaste nueva foto dlib \", nombre_foto)\n",
    "\n",
    "            cv2.imwrite(path_nueva_foto+FORMATO, face_aligned_grey)\n",
    "            \n",
    "            cont += 1\n",
    "\n",
    "        cv2.imshow('Cara alineada', frame)\n",
    "        #cv2.imshow('Cara alineada', face_aligned)\n",
    "        #cv2.imshow('Cara alineada', face_aligned_grey)\n",
    "\n",
    "    \n",
    "    if key == ord ('q'):\n",
    "        seguir=False\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las decisiones de implementacion fueron las siguientes:\n",
    "\n",
    "#### . Consumo de imagenes del dataset : al principio consumia todo el dataset de una, pero saturaba la RAM. Para solucionarlo se decidio consumir las imagenes con un Generador de Imagenes, recolectando de a batches las imagenes de prueba sin arruinar la RAM;\n",
    "\n",
    "#### . Definicion del modelo y fine tuning aplicado a rostros\n",
    "\n",
    "#### . Hiperparametros, compilacion y entrenamiento del modelo\n",
    "\n",
    "#### . Test del modelo\n",
    "\n",
    "#### . Predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import PIL\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generador de imagenes\n",
    "\n",
    "Utilizo el generador de batches de imagenes provisto por Keras , para cargar imagenes de a batches de forma mas simple y robusta.\n",
    "\n",
    "De lo contrario, cargando todo el dataset de una, satura la RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 459 images belonging to 5 classes.\n",
      "Found 151 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "generador = ImageDataGenerator(validation_split=0.25,\n",
    "                               rescale=1./255,\n",
    "                               shear_range = 0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "#dir_dataset = '/Users/andresmanzalini/Documents/Datasets/Caras/Familia'\n",
    "dir_dataset = '/home/andres/Documentos/IA/Datasets/Caras/Familia'\n",
    "\n",
    "\n",
    "training_generator = generador.flow_from_directory(dir_dataset,\n",
    "                                                   target_size = (224,224),\n",
    "                                                   batch_size=8,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='training')\n",
    "\n",
    "validation_generator = generador.flow_from_directory(dir_dataset,\n",
    "                                                     target_size = (224,224),\n",
    "                                                     batch_size=8,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas = training_generator.class_indices\n",
    "cant_ids = training_generator.num_classes\n",
    "cant_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andres', 'Lu', 'Ma', 'Martin', 'Paula']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(etiquetas.keys()) \n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "\n",
    "default_size=(224,224,3)\n",
    "#default_size=(224,224,1)\n",
    "\n",
    "\n",
    "# entrenar con imagenes blanco y negro -> 224, 224, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(input_shape=(default_size), weights='imagenet', include_top=False)\n",
    "\n",
    "#congela las capas del modelo original salvo la ultima\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,552,005\n",
      "Trainable params: 1,837,317\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# retocar estas ultimas capas segun la cantidad de personas a identificar y la salida de (7,7,512)\n",
    "# afinar las ultimas capas densas fully connected segun cantidad de ids\n",
    "\n",
    "c1 = Conv2D(256, (3,3), activation='relu')(vgg.output)\n",
    "#c2 = Conv2D(64, (3,3), activation='relu')(c1)\n",
    "p1 = MaxPooling2D(2,2)(c1)\n",
    "\n",
    "f = Flatten()(p1) \n",
    "\n",
    "d1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(f) \n",
    "\n",
    "dr = Dropout(0.25)(d1)\n",
    "\n",
    "d2 = Dense(256, activation='relu')(dr)\n",
    "\n",
    "#jugar con los parametros de estas ultimas capas\n",
    "out = Dense(cant_ids, activation='softmax')(d2) \n",
    "\n",
    "\n",
    "\n",
    "model = Model(outputs=out, inputs=vgg.input) \n",
    "    \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilacion y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "tensorflow.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda3/envs/envDeepLearning/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "58/58 [==============================] - 422s 7s/step - loss: 6.0972 - accuracy: 0.5373 - val_loss: 2.1706 - val_accuracy: 0.7947\n",
      "Epoch 2/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 1.7079 - accuracy: 0.8817 - val_loss: 1.1243 - val_accuracy: 0.9404\n",
      "Epoch 3/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 0.9395 - accuracy: 0.9631 - val_loss: 0.8433 - val_accuracy: 0.9073\n",
      "Epoch 4/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 0.6408 - accuracy: 0.9700 - val_loss: 0.6428 - val_accuracy: 0.9404\n",
      "Epoch 5/20\n",
      "58/58 [==============================] - 440s 8s/step - loss: 0.4352 - accuracy: 0.9785 - val_loss: 0.4381 - val_accuracy: 0.9404\n",
      "Epoch 6/20\n",
      "58/58 [==============================] - 440s 8s/step - loss: 0.2951 - accuracy: 0.9947 - val_loss: 0.3176 - val_accuracy: 0.9735\n",
      "Epoch 7/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 0.3197 - accuracy: 0.9496 - val_loss: 0.5415 - val_accuracy: 0.9007\n",
      "Epoch 8/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 0.1979 - accuracy: 0.9911 - val_loss: 0.2931 - val_accuracy: 0.9404\n",
      "Epoch 9/20\n",
      "58/58 [==============================] - 443s 8s/step - loss: 0.1411 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9272\n",
      "Epoch 10/20\n",
      "58/58 [==============================] - 442s 8s/step - loss: 0.1164 - accuracy: 0.9970 - val_loss: 0.2251 - val_accuracy: 0.9470\n",
      "Epoch 11/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 0.1192 - accuracy: 0.9916 - val_loss: 0.3484 - val_accuracy: 0.8940\n",
      "Epoch 12/20\n",
      "58/58 [==============================] - 443s 8s/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9073\n",
      "Epoch 13/20\n",
      "58/58 [==============================] - 442s 8s/step - loss: 0.0701 - accuracy: 0.9962 - val_loss: 0.2905 - val_accuracy: 0.9007\n",
      "Epoch 14/20\n",
      "58/58 [==============================] - 441s 8s/step - loss: 0.1600 - accuracy: 0.9540 - val_loss: 0.2330 - val_accuracy: 0.9603\n",
      "Epoch 15/20\n",
      "58/58 [==============================] - 443s 8s/step - loss: 0.1432 - accuracy: 0.9836 - val_loss: 0.3374 - val_accuracy: 0.9139\n",
      "Epoch 16/20\n",
      "58/58 [==============================] - 442s 8s/step - loss: 0.1149 - accuracy: 0.9969 - val_loss: 0.3417 - val_accuracy: 0.9139\n",
      "Epoch 17/20\n",
      "58/58 [==============================] - 446s 8s/step - loss: 0.1637 - accuracy: 0.9716 - val_loss: 0.5278 - val_accuracy: 0.8344\n",
      "Epoch 18/20\n",
      "58/58 [==============================] - 601s 10s/step - loss: 0.1137 - accuracy: 0.9846 - val_loss: 0.2870 - val_accuracy: 0.9007\n",
      "Epoch 19/20\n",
      "58/58 [==============================] - 490s 8s/step - loss: 0.0786 - accuracy: 0.9954 - val_loss: 0.3059 - val_accuracy: 0.8940\n",
      "Epoch 20/20\n",
      "58/58 [==============================] - 447s 8s/step - loss: 0.0652 - accuracy: 0.9983 - val_loss: 0.1761 - val_accuracy: 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda3/envs/envDeepLearning/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22026246786117554, 0.9271523356437683]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        #epochs=15,\n",
    "                        epochs=20,\n",
    "                        steps_per_epoch=len(training_generator),\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        callbacks=[es],\n",
    "                        workers=4)\n",
    "\n",
    "\n",
    "# hacer un modulo que entrene con gpu!\n",
    "# VER COMO ENTRENAR EN PARALELO! gpu o worwers=4?\n",
    "\n",
    "model.evaluate_generator(generator=validation_generator,\n",
    "                         steps=len(validation_generator))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PRUEBAS\n",
    " \n",
    "\n",
    "Precision buena, de .97 \n",
    "\n",
    "Perdida considerable, de .16\n",
    "\n",
    "Hay undefitting \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Aclaracion: Independientemente de la plataforma de entrenamiento (jupyter notebook o desde la ejecucion local del script) , los resultados de precision son buenos, de entre 0.95 y 0.98\n",
    "&nbsp;\n",
    "\n",
    "El problema se da en los resultados de perdida...\n",
    "&nbsp;\n",
    "\n",
    "El entrenamiento del modelo en el jupyter notebook presenta resultados de perdida altos, de entre 0.1 y 0.2\n",
    "Por eso es mejor entrenar desde el script entrenarModelo.py , el cual presenta resultados de perdida validos, de entre 0.03 y 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear el modelo es posible utilizar el modelo recientemente entrenado; o un modelo previamente guardado.\n",
    "\n",
    "\n",
    "Si los resultados son buenos, puedo hacer las predicciones desde el modelo recien entrenado.\n",
    "\n",
    "Si no, es posible cargar el modelo desde disco.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "#model.save('reconocimientoFacial_tf2.h5')\n",
    "\n",
    "#def cargar_modelo():\n",
    "#modelo_cargado = load_model('faceRecognition_model.h5')#NOMBRE_MODELO\n",
    "#    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elijo usar modelo recien entrenado (en RAM) o usar el modelo guardado en disco ??\n",
    "\n",
    "\n",
    "#modelo = load_model('reconocimientoFacial.h5')\n",
    "\n",
    "modelo = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: visualkeras in /home/andres/anaconda3/envs/envDeepLearning/lib/python3.8/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/andres/anaconda3/envs/envDeepLearning/lib/python3.8/site-packages (from visualkeras) (8.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "#visualkeras.layered_view(modelo)\n",
    "visualkeras.layered_view(modelo, to_file='vgg16.png').show() # write and show\n",
    "#visualkeras.layered_view(modelo, legend=True) #, font=font)  # font is optional!\n",
    "#visualkeras.layered_view(model, type_ignore=[ZeroPadding2D, Dropout, Flatten])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones estaticas\n",
    "\n",
    "\n",
    "Del disco al programa, en formato .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n",
    "\n",
    "#convert the images from RGB to BGR, then will zero-center each color channel with\n",
    "#respect to the ImageNet dataset, without scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=224x224 at 0x1494531D0>\n",
      "float32\n",
      "[[1.0000000e+00 1.6545037e-32 1.1565375e-32 2.5648252e-31 2.1980701e-28]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Andres'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = '/Users/andresmanzalini/Documents/Andres_Prueba.jpg'\n",
    "\n",
    "img = image.load_img(im, target_size=(224, 224))   #MAL!! el modelo o la prediccion?\n",
    "print(img)\n",
    "x = image.img_to_array(img)\n",
    "print(x.dtype)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print('x expandida ',x)\n",
    "x = preprocess_input(x)     #RARO. esto parece que esta mal! que hace con la imagen?\n",
    "#print('x preprocess ', x)  #wat?\n",
    "prediccion = model.predict(x)\n",
    "print(prediccion)\n",
    "pred = np.argmax(prediccion) \n",
    "pred\n",
    "tags[pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicciones  [1.0000000e+00 1.6545037e-32 1.1565375e-32 2.5648252e-31 2.1980701e-28]\n",
      "etiqueta  Andres\n",
      "prediccion: 1.000\n"
     ]
    }
   ],
   "source": [
    "preds = prediccion[0][:]\n",
    "print('predicciones ',preds)\n",
    "print('etiqueta ',tags[pred])\n",
    "print(\"prediccion: {0:.3f}\". format(preds[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones por webcam\n",
    "\n",
    "Usa opencv y dlib.\n",
    "\n",
    "Tener en cuenta que las imagenes del dataset tienen el formato RGB, predefinido por dlib al alinear las caras con chip_align(face), de la libreria PIL.\n",
    "\n",
    "Por eso hay que ser consistentes con el formato de salida de la camara web, para entrenar y predecir con los mismos formatos y tipos de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutar a partir de aca!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV\n",
    "data_path_cv2 = cv2.__path__[0]+'/data/'\n",
    "haar_type = 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "face_cascada = cv2.CascadeClassifier(data_path_cv2+haar_type)\n",
    "\n",
    "\n",
    "#DLIB\n",
    "path_DLIBmodel = os.path.dirname(os.getcwd())+'/shape_predictor_68_face_landmarks.dat'\n",
    "land_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(path_DLIBmodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma: : [0.9761529]\n",
      "Ma: : [0.966515]\n",
      "Ma: : [0.9630064]\n",
      "Ma: : [0.9673304]\n",
      "Ma: : [0.93011206]\n",
      "Andres: : [0.9997365]\n",
      "Andres: : [0.99989474]\n",
      "Andres: : [0.9995871]\n",
      "Andres: : [0.999908]\n",
      "Andres: : [0.99979025]\n",
      "Andres: : [0.99991715]\n",
      "Andres: : [0.9998454]\n",
      "Andres: : [0.9999331]\n",
      "Andres: : [0.9996718]\n",
      "Andres: : [0.9997564]\n",
      "Andres: : [0.99979895]\n",
      "Andres: : [0.99594057]\n",
      "Andres: : [0.97243506]\n",
      "Andres: : [0.99741155]\n",
      "Andres: : [0.99664813]\n",
      "Andres: : [0.99862635]\n",
      "Andres: : [0.98796785]\n",
      "Andres: : [0.9024555]\n",
      "Andres: : [0.9896152]\n",
      "Andres: : [0.98540086]\n",
      "Andres: : [0.98913515]\n"
     ]
    }
   ],
   "source": [
    "seguir = True\n",
    "while seguir:\n",
    "    ret, frame = video.read()\n",
    "    #gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #sobreescribo formato de salida de GBR a RGB \n",
    "    gris = cv2.cvtColor(frameRGB, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    key = cv2.waitKey(1) \n",
    "\n",
    "    caras_dlib = land_detector(gris,1)\n",
    "\n",
    "    for cara in caras_dlib:\n",
    "        x = cara.left()\n",
    "        y = cara.top()\n",
    "        w = cara.right() - x\n",
    "        h = cara.bottom() - y\n",
    "        \n",
    "        landmarks = predictor(gris, cara)\n",
    "        face_aligned = dlib.get_face_chip(frame, landmarks, 224)\n",
    "        \n",
    "        face_aligned_32 = np.asarray(face_aligned, dtype='float32') \n",
    "        #print('face aligned 32 ', face_aligned_32)\n",
    "        im_expand = np.expand_dims(face_aligned_32, axis=0) \n",
    "        #print('expand ', im_expand.shape)\n",
    "        im_normalizada = (im_expand - np.min(im_expand)) / (np.max(im_expand) - np.min(im_expand))\n",
    "        #normalizando predice probabilidades!\n",
    "        \n",
    "        prediccion = modelo.predict(im_normalizada)\n",
    "        \n",
    "        pred = np.argmax(prediccion)\n",
    "        proba = prediccion[:,pred]\n",
    "        tag = tags[pred]+\": \"\n",
    "\n",
    "        \n",
    "        if proba > .7: # & reconoce al mismo id durante 2s\n",
    "            print('{}: {}'.format(tag, proba))\n",
    "            cv2.putText(frame, tag+str(proba), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (cara.right(),cara.bottom()), (0,255,0), 3)\n",
    "        \n",
    "        for n in range(0,68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x,y), 3, (255,0,0))\n",
    "\n",
    "        cv2.imshow('Cara alineada', face_aligned)\n",
    "\n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "    \n",
    "    if key == ord ('q'):\n",
    "        seguir=False\n",
    "        \n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo???\n",
    "\n",
    "#def guardar_modelo(modelo):\n",
    "#    modelo.save('./faceRecognition_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#    del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesamiento de imagenes esta hecho con openCV. Esta libreria provee la funcionalidad para obtener imagenes y procesarlas. Permite jugar con los filtros y transformaciones geometricas.\n",
    "\n",
    "\n",
    "El reconocimiento facial esta hecho con haarcascade y con el modelo preentrenado de la libreria dlib,  *shape_predictor_68_face_landmarks.dat*\n",
    "\n",
    "\n",
    "Respecto al Deep Learning, el modelo VGG16 es bueno para el reconocimiento facial, ya que fue entrenado para extraer carecteristicas mas generales de las imagenes. \n",
    "\n",
    "La clave para la precision esta en la combinacion entre la deteccion de expresiones faciales (modelo preentrenado facial_landmarks_68), y el modelo preentrenado de Keras, VGG16 \n",
    "\n",
    "\n",
    "Los resultados son bastante precisos a pesar de la poca informacion de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En desarrollo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes siamesas \n",
    "\n",
    "\n",
    "One-shot learning\n",
    "\n",
    "Comparo imagenes del mismo subconjunto y calculo el triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras import Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#uso de triplet loss.\n",
    "#compara de a 3 medidas a la vez, y se va aproximando al positivo a medida que entrena el algoritmo\n",
    "\n",
    "vgg = VGG16(input_shape=(default_size), weights='imagenet', include_top=False)#, classes=3)\n",
    "\n",
    "#vgg.summary()\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flatten()(vgg.output) #aplano vgg con sus respectivos pesos definidos en imagenet\n",
    "\n",
    "x = BatchNormalization()(f)\n",
    "\n",
    "d = Dropout(0.2)(x)\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01))\n",
    "out = Dense(4, activation='softmax')(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 25088)             100352    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 100356    \n",
      "=================================================================\n",
      "Total params: 14,915,396\n",
      "Trainable params: 150,532\n",
      "Non-trainable params: 14,764,864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresmanzalini/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=vgg.input, outputs=out) #input model o vgg?\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'vgg16_4/block5_pool/MaxPool:0' shape=(?, 7, 7, 512) dtype=float32>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seq_model = tf.keras.Sequential(vgg)\n",
    "\n",
    "left_input = Input(shape=default_size)\n",
    "right_input = Input(shape=default_size)\n",
    "\n",
    "#model = Sequential()\n",
    "#left_output = model(left_input)\n",
    "right_output = vgg(right_input)\n",
    "left_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_euclid = Lambda(lambda tensors : K.abs( tensors[0] - tensors[1] ))([left_output , right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = Dense(1 , activation='sigmoid')(distance_euclid)\n",
    "\n",
    "#model = Model(input=vgg.input, outputs=out) #input model o vgg?\n",
    "\n",
    "model = Model([left_input,right_input], outputs)\n",
    "model = Model(inputs=[left_input, right_input], outputs=outs)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 7, 7, 512)    14714688    input_32[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 7, 7, 512)    0           vgg16[1][0]                      \n",
      "                                                                 vgg16[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 7, 7, 1)      513         lambda_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articulos sobre redes neuronales siamesas\n",
    "\n",
    "# https://medium.com/predict/face-recognition-from-scratch-using-siamese-networks-and-tensorflow-df03e32f8cd0\n",
    "\n",
    "# https://www.codeproject.com/Articles/1253224/Keras-Implementation-of-Siamese-like-Networks\n",
    "\n",
    "# https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1503.03832.pdf\n",
    "\n",
    "# https://spanish.agatetepe.com.br/hacer-su-propio-sistema-de-reconocimiento-de-rostros/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el uso de vgg16 requiere la mencion del sgte paper \n",
    "# https://arxiv.org/abs/1409.1556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo futuro "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto a los datos de entrenamiento y prueba, lo ideal seria hacer un script que cargue automaticamente los datasets cada vez que identifica (durante un minimo intervalo de tiempo) a una persona ya registrada en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien es importante implementar FaceNet con el mismo dataset, para el mismo problema y comprobar los resultado.\n",
    "Esto permite definir que tan bien predice una red neuronal convolucional simple (VGG16) comparado con LA red neuronal convolucional FaceNet "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
