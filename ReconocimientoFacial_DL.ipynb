{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento y Clasificacion de rostros con Redes Neuronales Convolucionales en Keras\n",
    "\n",
    "La idea del proyecto es implementar distintas arquitecturas de redes neuronales para el procesamiento e identificacion de rostros, a partir de los modelos preentrenados disponible en Keras y de los distintos modelos en los papers mencionados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para personalizar el problema a partir del script faceDetection.py, hay que crear una carpeta que contenga el dataset, para ir caragandola con cada ejecucion de detectarProcesar_cara.py con imagenes croppeadas y alineadas, listas para entrenar los modelos.\n",
    "\n",
    "Para el correcto funcionamiento es necesaria la libreria DLIB con el modelo preentrenado shape_predictor_68_face_landamarks.dat, disponible en https://github.com/davisking/dlib-models\n",
    "\n",
    "Hay que ingresar como parametro la etiqueta de la persona a identificar. \n",
    "La direccion del dataset dentro del script \n",
    "Ejecutarlo con el comando: python detectarProcesar_cara.py ETIQUETA\n",
    "\n",
    "Con 's' sacas fotos, con 'q' salis.\n",
    "\n",
    "Aclaracion: esta forma manual de cargar el dataset no es del todo efectiva... Cargando foto a foto el dataset se hace tedioso, considerando que un dataset chico tiene miles de imagenes.\n",
    "Lo ideal seria hacer un script que cargue automaticamente los datasets cada vez que identifica (durante un minimo intervalo de tiempo) a una persona ya registrada en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import PIL\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 185 images belonging to 8 classes.\n",
      "Found 56 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "generador = ImageDataGenerator(validation_split=0.25,\n",
    "                               rescale=1./255,\n",
    "                               shear_range = 0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "\n",
    "training_generator = generador.flow_from_directory('/Users/andresmanzalini/Documents/Datasets',\n",
    "                                                   target_size = (224,224),\n",
    "                                                   batch_size=8,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='training')\n",
    "\n",
    "validation_generator = generador.flow_from_directory('/Users/andresmanzalini/Documents/Datasets',\n",
    "                                                     target_size = (224,224),\n",
    "                                                     batch_size=8,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetas = training_generator.class_indices\n",
    "cant_ids = training_generator.num_classes\n",
    "cant_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andres', 'Bene', 'Bruga', 'D', 'Ma', 'Martin', 'Paula', 'V']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(etiquetas.keys()) \n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andres', 'Bene', 'Bruga', 'D', 'Ma', 'Martin', 'Paula', 'V']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#otra alternativa, desde os\n",
    "#hacer predicciones definitivas y subir modelo a gitbazo\n",
    "#es mejor la del generador\n",
    "tg = os.listdir('/Users/andresmanzalini/Documents/Datasets')\n",
    "if '.DS_Store' in tg:\n",
    "    tg.remove('.DS_Store')\n",
    "tg.sort()\n",
    "tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definicion del modelo y entrenamiento - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "\n",
    "default_size=(224,224,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(input_shape=(default_size), weights='imagenet', include_top=False)\n",
    "\n",
    "#congela las capas del modelo original salvo la ultima\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "vgg.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 5, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 16,552,776\n",
      "Trainable params: 1,838,088\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# retocar estas ultimas capas segun la cantidad de personas a identificar y la salida de (7,7,512)\n",
    "# afinar las ultimas capas densas fully connected segun cantidad de ids\n",
    "\n",
    "c1 = Conv2D(256, (3,3), activation='relu')(vgg.output)\n",
    "#c2 = Conv2D(64, (3,3), activation='relu')(c1)\n",
    "p1 = MaxPooling2D(2,2)(c1)\n",
    "\n",
    "f = Flatten()(p1) \n",
    "\n",
    "d1 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(f) \n",
    "\n",
    "dr = Dropout(0.25)(d1)\n",
    "\n",
    "d2 = Dense(256, activation='relu')(dr)\n",
    "\n",
    "#jugar con los parametros de estas ultimas capas\n",
    "out = Dense(cant_ids, activation='softmax')(d2) \n",
    "\n",
    "#ejemplo para identificar 8 personas\n",
    "\n",
    "model = Model(outputs=out, inputs=vgg.input) \n",
    "    \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "24/24 [==============================] - 96s 4s/step - loss: 6.7114 - acc: 0.4679 - val_loss: 4.5332 - val_acc: 0.6607\n",
      "Epoch 2/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 3.4219 - acc: 0.7914 - val_loss: 2.6989 - val_acc: 0.8214\n",
      "Epoch 3/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 2.1281 - acc: 0.8852 - val_loss: 1.8924 - val_acc: 0.8750\n",
      "Epoch 4/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 1.5479 - acc: 0.9374 - val_loss: 2.0151 - val_acc: 0.6429\n",
      "Epoch 5/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 1.3030 - acc: 0.9374 - val_loss: 1.5088 - val_acc: 0.8571\n",
      "Epoch 6/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 1.0699 - acc: 0.9687 - val_loss: 1.0621 - val_acc: 0.9286\n",
      "Epoch 7/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.8635 - acc: 0.9739 - val_loss: 1.1931 - val_acc: 0.8571\n",
      "Epoch 8/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.7700 - acc: 0.9687 - val_loss: 0.8846 - val_acc: 0.9286\n",
      "Epoch 9/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.6428 - acc: 0.9791 - val_loss: 0.8073 - val_acc: 0.9286\n",
      "Epoch 10/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.5390 - acc: 0.9948 - val_loss: 0.6686 - val_acc: 0.9107\n",
      "Epoch 11/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.4727 - acc: 0.9948 - val_loss: 0.6457 - val_acc: 0.9464\n",
      "Epoch 12/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.4081 - acc: 0.9896 - val_loss: 0.4976 - val_acc: 0.9286\n",
      "Epoch 13/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.3746 - acc: 0.9844 - val_loss: 0.4176 - val_acc: 0.9464\n",
      "Epoch 14/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.3823 - acc: 0.9739 - val_loss: 0.4834 - val_acc: 0.9286\n",
      "Epoch 15/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.2953 - acc: 0.9948 - val_loss: 0.4784 - val_acc: 0.9464\n",
      "Epoch 16/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.2530 - acc: 1.0000 - val_loss: 0.4347 - val_acc: 0.9464\n",
      "Epoch 17/40\n",
      "24/24 [==============================] - 93s 4s/step - loss: 0.2147 - acc: 1.0000 - val_loss: 0.4764 - val_acc: 0.9107\n",
      "Epoch 18/40\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.1852 - acc: 1.0000 - val_loss: 0.2954 - val_acc: 0.9643\n",
      "Epoch 19/40\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.1586 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.9464\n",
      "Epoch 20/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.1373 - acc: 1.0000 - val_loss: 0.2794 - val_acc: 0.9643\n",
      "Epoch 21/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.1210 - acc: 1.0000 - val_loss: 0.2646 - val_acc: 0.9464\n",
      "Epoch 22/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.2239 - acc: 0.9791 - val_loss: 0.3165 - val_acc: 0.9107\n",
      "Epoch 23/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.2330 - acc: 0.9791 - val_loss: 0.5319 - val_acc: 0.9107\n",
      "Epoch 24/40\n",
      "24/24 [==============================] - 95s 4s/step - loss: 0.2650 - acc: 0.9739 - val_loss: 0.4263 - val_acc: 0.9286\n",
      "Epoch 25/40\n",
      "24/24 [==============================] - 96s 4s/step - loss: 0.2563 - acc: 0.9739 - val_loss: 0.3739 - val_acc: 0.9286\n",
      "Epoch 26/40\n",
      "24/24 [==============================] - 95s 4s/step - loss: 0.1750 - acc: 1.0000 - val_loss: 0.3904 - val_acc: 0.9464\n",
      "Epoch 27/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.1903 - acc: 0.9791 - val_loss: 0.5720 - val_acc: 0.9286\n",
      "Epoch 28/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.1437 - acc: 1.0000 - val_loss: 0.2737 - val_acc: 0.9643\n",
      "Epoch 29/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.1214 - acc: 1.0000 - val_loss: 0.3408 - val_acc: 0.9286\n",
      "Epoch 30/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.1045 - acc: 1.0000 - val_loss: 0.3098 - val_acc: 0.9464\n",
      "Epoch 31/40\n",
      "24/24 [==============================] - 102s 4s/step - loss: 0.0912 - acc: 1.0000 - val_loss: 0.3557 - val_acc: 0.9286\n",
      "Epoch 32/40\n",
      "24/24 [==============================] - 94s 4s/step - loss: 0.0803 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 0.9286\n",
      "Epoch 33/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0713 - acc: 1.0000 - val_loss: 0.2726 - val_acc: 0.9286\n",
      "Epoch 34/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0793 - acc: 0.9948 - val_loss: 0.3093 - val_acc: 0.9464\n",
      "Epoch 35/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0971 - acc: 0.9896 - val_loss: 0.2772 - val_acc: 0.9464\n",
      "Epoch 36/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0850 - acc: 0.9948 - val_loss: 0.2064 - val_acc: 0.9643\n",
      "Epoch 37/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0657 - acc: 1.0000 - val_loss: 0.2949 - val_acc: 0.9464\n",
      "Epoch 38/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.2325 - val_acc: 0.9464\n",
      "Epoch 39/40\n",
      "24/24 [==============================] - 90s 4s/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.2105 - val_acc: 0.9464\n",
      "Epoch 40/40\n",
      "24/24 [==============================] - 92s 4s/step - loss: 0.0666 - acc: 0.9948 - val_loss: 0.3162 - val_acc: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2238596768251487, 0.9285714285714286]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "\n",
    "h = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        epochs=40,\n",
    "                        steps_per_epoch=len(training_generator),\n",
    "                        validation_steps=len(validation_generator),\n",
    "                        callbacks=[es])\n",
    "\n",
    "model.evaluate_generator(generator=validation_generator,\n",
    "                         steps=len(validation_generator))\n",
    "\n",
    "\n",
    "#def guardar_modelo(modelo):\n",
    "#    modelo.save('./faceRecognition_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#    del modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PRUEBAS\n",
    "\n",
    "Al principio probable underfitting. A medida que agregas imagenes al dataset balanceado, los valores de perdida y precision se acomodan... \n",
    "Ya con el dataset balanceado, en algun momento va a haber overfitting. Controlarlo de acuerdo al dataset y la cantidad de ids con los hiperparametros de las ultimas capas Densas, dropout y regularizers.\n",
    "\n",
    "\n",
    "    con Conv2D(256, (3,3), relu) + maxPooling2D(2,2), Dropout(0.25) \n",
    "        # val_loss=0.2, val_acc=0.965 con 15 epochs \n",
    "    \n",
    "    \n",
    "    con Conv2D(128, (3,3), relu) + maxPooling2D(2,2), Dropout(0.25) \n",
    "        # val_loss=0.275, val_acc=0.931\n",
    "\n",
    "    \n",
    "    con Regularizers en Conv2D =>  muchisimo error inicial\n",
    "        con kernel_regularizer=0.01 y activity_regularizer=0.01) \n",
    "        # val_loss=2.310, val_acc=0.309   en 20 epochs\n",
    "        \n",
    "        con activity_regularizer(0.01)  => 80. de error inicial! baja a 2.0 al finalizar 1er epoch\n",
    "        # val_loss=1.933, val_acc=0.261\n",
    "    \n",
    "        con kernel_regularizer(0.01)  => bueno\n",
    "        # val_loss=0.694, val_acc=0.904   en 20 epochs. ojo.. \n",
    "        # val_loss=0.429, val_acc=0.952   en 50 epochs\n",
    "        # val_loss=0.195, val_acc=0.952   en 100 epochs\n",
    "\n",
    "\n",
    "\n",
    "usar 1 capa convolucional 2D es mas efectivo que usar 2 Conv2D\n",
    "\n",
    "\n",
    "\n",
    "agregando 2 capas densas fully-connected\n",
    "    \n",
    "    \n",
    "    con Dense(512, relu) + Dense(256, relu) \n",
    "        #val_loss=0.179, val_acc=0.921   con 15 epochs\n",
    "        #val_loss=0.115, val_acc=0.947   con 20 epochs\n",
    "        #val_loss=0.547, val_acc=0.921   con 50 epochs\n",
    "        #val_loss=0.36,  val_acc=0.928    '' \n",
    "    \n",
    "    \n",
    "    con regularizers en capas densas\n",
    "    \n",
    "        kernel_regularizer solo en Dense(512,relu) => buena precision. error baja despacito a tasa constante\n",
    "            # val_loss=0.212, val_acc=0.952  en 25 epochs. OJO! Mejor que regularizar solo la capa Conv2D\n",
    "            \n",
    "            # val_loss=0.254, val_acc=0.962  en 150 epochs\n",
    "        \n",
    "        activity_regularizer en Dense(512,relu) => asco\n",
    "            # val_loss=1.880, val_acc=0.285\n",
    "        \n",
    "        \n",
    "        kernel_regularizer solo en Dense(256,relu) => 50/50\n",
    "            # val_loss=0.498, val_acc=0.904  en 25 epochs  \n",
    "        \n",
    "        kernel_regularizer en ambas capas => rrrrrada. una banda de loss para lo que deberia ser\n",
    "            # val_loss=0.374, val_acc=0.928\n",
    "            \n",
    "        \n",
    "        con dropout(0.25) entre capas Densas => suaviza error. mas o menos lo mismo\n",
    "            # val_loss=0.223, acc=0.928\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#Si quiero guardo y/o cargo modelo desde disco con las funciones de abajo\n",
    "#sino hago predicciones con el modelo recien entrenado en RAM\n",
    "\n",
    "#model.save('reconocimientoFacial.h5')\n",
    "\n",
    "#def cargar_modelo():\n",
    "#modelo_cargado = load_model('faceRecognition_model.h5')#NOMBRE_MODELO\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones estaticas\n",
    "Del disco al programa, en formato .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n",
    "\n",
    "#convert the images from RGB to BGR, then will zero-center each color channel with\n",
    "#respect to the ImageNet dataset, without scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_yo = '/Users/andresmanzalini/Documents/Andres_Prueba.jpg'\n",
    "im_v = '/Users/andresmanzalini/Documents/V.jpg'\n",
    "im_b = '/Users/andresmanzalini/Documents/Bn.jpg'\n",
    "im_d = '/Users/andresmanzalini/Documents/D.jpg'\n",
    "\n",
    "img = image.load_img(im_d, target_size=(224, 224))   #MAL!! el modelo o la prediccion?\n",
    "print(img)\n",
    "x = image.img_to_array(img)\n",
    "print(x.dtype)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print('x expandida ',x)\n",
    "x = preprocess_input(x)     #RARO. esto parece que esta mal! que hace con la imagen?\n",
    "#print('x preprocess ', x)  #wat?\n",
    "prediccion = model.predict(x)\n",
    "print(prediccion)\n",
    "pred = np.argmax(prediccion) \n",
    "pred\n",
    "tags[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicciones  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.0123867e-13 1.0000000e+00]\n",
      "etiqueta  V\n",
      "prediccion: 1.000\n"
     ]
    }
   ],
   "source": [
    "preds = prediccion[0][:]\n",
    "print('predicciones ',preds)\n",
    "print('etiqueta ',tags[pred])\n",
    "print(\"prediccion: {0:.3f}\". format(preds[pred]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones por webcam\n",
    "\n",
    "Usa opencv y dlib.\n",
    "\n",
    "Tener en cuenta que las imagenes del dataset tienen el formato RGB, predefinido por dlib al alinear las caras con chip_align(face), de la libreria PIL.\n",
    "\n",
    "Por eso hay que ser consistentes con el formato de salida de la camara web, para entrenar y predecir con los mismos formatos y tipos de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef preprocess_input_keras(x, data_format=None, version=1):\\n    x_temp = np.copy(x)\\n    if data_format is None:\\n        data_format = K.image_data_format()\\n    assert data_format in {'channels_last', 'channels_first'}\\n\\n    if version == 1:\\n        if data_format == 'channels_first':\\n            x_temp = x_temp[:, ::-1, ...]\\n            x_temp[:, 0, :, :] -= 93.5940\\n            x_temp[:, 1, :, :] -= 104.7624\\n            x_temp[:, 2, :, :] -= 129.1863\\n        else:\\n            x_temp = x_temp[..., ::-1]\\n            x_temp[..., 0] -= 93.5940\\n            x_temp[..., 1] -= 104.7624\\n            x_temp[..., 2] -= 129.1863\\n\\n    elif version == 2:\\n        if data_format == 'channels_first':\\n            x_temp = x_temp[:, ::-1, ...]\\n            x_temp[:, 0, :, :] -= 91.4953\\n            x_temp[:, 1, :, :] -= 103.8827\\n            x_temp[:, 2, :, :] -= 131.0912\\n        else:\\n            x_temp = x_temp[..., ::-1]\\n            x_temp[..., 0] -= 91.4953\\n            x_temp[..., 1] -= 103.8827\\n            x_temp[..., 2] -= 131.0912\\n    else:\\n        raise NotImplementedError\\n\\n    return x_temp\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "#flashero metodo de preprocesamiento de Keras. Por que normaliza asi?\n",
    "\n",
    "'''\n",
    "def preprocess_input_keras(x, data_format=None, version=1):\n",
    "    x_temp = np.copy(x)\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "    if version == 1:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 93.5940\n",
    "            x_temp[:, 1, :, :] -= 104.7624\n",
    "            x_temp[:, 2, :, :] -= 129.1863\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 93.5940\n",
    "            x_temp[..., 1] -= 104.7624\n",
    "            x_temp[..., 2] -= 129.1863\n",
    "\n",
    "    elif version == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x_temp = x_temp[:, ::-1, ...]\n",
    "            x_temp[:, 0, :, :] -= 91.4953\n",
    "            x_temp[:, 1, :, :] -= 103.8827\n",
    "            x_temp[:, 2, :, :] -= 131.0912\n",
    "        else:\n",
    "            x_temp = x_temp[..., ::-1]\n",
    "            x_temp[..., 0] -= 91.4953\n",
    "            x_temp[..., 1] -= 103.8827\n",
    "            x_temp[..., 2] -= 131.0912\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return x_temp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andres: [0.60042363]\n",
      "D: [0.8542848]\n",
      "Andres: [0.98973316]\n",
      "Andres: [0.939084]\n",
      "Andres: [0.9936278]\n",
      "V: [0.9427046]\n",
      "D: [0.9400269]\n",
      "Bene: [0.7223402]\n",
      "Martin: [0.7451778]\n",
      "V: [0.67325854]\n",
      "Bene: [0.537768]\n",
      "Andres: [0.99560696]\n",
      "Andres: [0.99575883]\n",
      "Bene: [0.5785836]\n",
      "Ma: [0.8491212]\n",
      "Bene: [0.58626187]\n",
      "V: [0.65386915]\n",
      "V: [0.89591616]\n",
      "Martin: [0.87455845]\n",
      "Bene: [0.9732896]\n",
      "V: [0.77940804]\n",
      "Bene: [0.72129345]\n",
      "V: [0.99861026]\n",
      "V: [0.9986958]\n",
      "Bene: [0.8436593]\n",
      "Bene: [0.96044225]\n",
      "Bene: [0.9726428]\n",
      "V: [0.9998073]\n",
      "V: [0.99998367]\n",
      "Martin: [0.5111512]\n",
      "Bene: [0.729632]\n",
      "Bene: [0.61810094]\n",
      "Bene: [0.9176851]\n",
      "Bene: [0.97441995]\n",
      "Bene: [0.947715]\n",
      "Bene: [0.9240215]\n",
      "Bene: [0.99361163]\n",
      "Bene: [0.98623115]\n",
      "Bene: [0.5911229]\n",
      "Martin: [0.7801086]\n",
      "Bruga: [0.5037425]\n",
      "Bene: [0.7230731]\n",
      "D: [0.914251]\n",
      "Andres: [0.9537152]\n",
      "Andres: [0.997106]\n",
      "Andres: [0.9722946]\n",
      "Andres: [0.7538743]\n",
      "Bene: [0.5984712]\n",
      "V: [0.50401884]\n",
      "V: [0.8029283]\n",
      "Bene: [0.6041724]\n",
      "Bene: [0.87348586]\n",
      "Ma: [0.5421044]\n",
      "Bene: [0.92360276]\n",
      "Andres: [0.9999702]\n",
      "Andres: [0.95340073]\n",
      "Andres: [0.9999498]\n",
      "Andres: [0.9999987]\n",
      "Bruga: [0.6956442]\n",
      "V: [0.81807816]\n",
      "D: [0.72949225]\n",
      "V: [0.56777465]\n",
      "Andres: [0.7353947]\n",
      "Andres: [0.91748303]\n",
      "Andres: [0.98520297]\n",
      "Andres: [0.9804503]\n",
      "V: [0.78294635]\n",
      "Martin: [0.93060374]\n",
      "Ma: [0.9864203]\n",
      "Bruga: [0.6689783]\n",
      "V: [0.5795997]\n",
      "Bene: [0.7289448]\n",
      "D: [0.60224664]\n",
      "D: [0.97589934]\n",
      "D: [0.80578]\n",
      "D: [0.8465227]\n",
      "Andres: [0.99820924]\n",
      "Bene: [0.50016505]\n",
      "Andres: [0.9999498]\n",
      "Bene: [0.5954804]\n",
      "Andres: [0.99994564]\n",
      "Bene: [0.93693334]\n",
      "D: [0.997624]\n",
      "Andres: [0.87296385]\n",
      "Bene: [0.9560184]\n",
      "Andres: [0.997948]\n",
      "V: [0.9995152]\n",
      "Andres: [0.9975197]\n",
      "V: [0.99533737]\n",
      "Andres: [0.65919554]\n",
      "V: [0.9984236]\n",
      "Andres: [0.999524]\n",
      "V: [0.9607446]\n",
      "D: [0.9885352]\n",
      "V: [0.9692007]\n",
      "Andres: [0.9791631]\n",
      "V: [0.9903016]\n",
      "V: [0.98612994]\n",
      "Andres: [0.90646034]\n",
      "V: [0.99234104]\n",
      "Andres: [0.9894705]\n",
      "Bene: [0.73693633]\n",
      "Andres: [0.9997975]\n",
      "Bene: [0.99702317]\n",
      "Andres: [0.99741983]\n",
      "Bene: [0.99874383]\n",
      "Andres: [0.97366583]\n",
      "Bene: [0.99899644]\n",
      "Andres: [0.9623719]\n",
      "Bene: [0.9948624]\n",
      "Andres: [0.9844024]\n",
      "Bene: [0.9989059]\n",
      "Andres: [0.8407352]\n",
      "Bene: [0.9996327]\n",
      "D: [0.6543048]\n",
      "Bene: [0.9992393]\n",
      "Bene: [0.80020756]\n",
      "Bene: [0.99372005]\n",
      "V: [0.9740693]\n",
      "Bene: [0.93972725]\n",
      "Andres: [0.9999417]\n",
      "V: [0.9292073]\n",
      "Andres: [0.6194143]\n",
      "V: [0.85107714]\n",
      "Andres: [0.8253251]\n",
      "V: [0.5973355]\n",
      "V: [0.9784913]\n",
      "Bene: [0.50557137]\n",
      "V: [0.6695235]\n",
      "V: [0.94889355]\n",
      "D: [0.88064945]\n",
      "V: [0.58143413]\n",
      "D: [0.9513181]\n",
      "V: [0.9429882]\n",
      "D: [0.9755962]\n",
      "Bene: [0.87459767]\n",
      "D: [0.9851741]\n",
      "V: [0.9784476]\n",
      "D: [0.7468177]\n",
      "V: [0.60371006]\n",
      "Andres: [0.9769663]\n",
      "Bene: [0.9651207]\n",
      "Andres: [0.999925]\n",
      "Bene: [0.99760383]\n",
      "Andres: [0.9998349]\n",
      "Bene: [0.9860189]\n",
      "Paula: [0.6341446]\n",
      "Bene: [0.9985941]\n",
      "Bene: [0.9969133]\n",
      "Ma: [0.7867265]\n",
      "Andres: [0.67379516]\n",
      "V: [0.6073124]\n"
     ]
    }
   ],
   "source": [
    "#OpenCV\n",
    "data_path_cv2 = cv2.__path__[0]+'/data/'\n",
    "haar_type = 'haarcascade_frontalface_default.xml'\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "face_cascada = cv2.CascadeClassifier(data_path_cv2+haar_type)\n",
    "\n",
    "\n",
    "#DLIB\n",
    "path_DLIBmodel = os.path.dirname(os.getcwd())+'/shape_predictor_68_face_landmarks.dat'\n",
    "land_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(path_DLIBmodel)\n",
    "\n",
    "\n",
    "seguir = True\n",
    "while seguir:\n",
    "    ret, frame = video.read()\n",
    "    #gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #sobreescribo formato de salida de GBR a RGB \n",
    "    gris = cv2.cvtColor(frameRGB, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    key = cv2.waitKey(1) \n",
    "\n",
    "    caras_dlib = land_detector(gris,1)\n",
    "\n",
    "    for cara in caras_dlib:\n",
    "        x = cara.left()\n",
    "        y = cara.top()\n",
    "        w = cara.right() - x\n",
    "        h = cara.bottom() - y\n",
    "        \n",
    "        landmarks = predictor(gris, cara)\n",
    "        face_aligned = dlib.get_face_chip(frame, landmarks, 224)\n",
    "        \n",
    "        face_aligned_32 = np.asarray(face_aligned, dtype='float32') \n",
    "        #print('face aligned 32 ', face_aligned_32)\n",
    "        im_expand = np.expand_dims(face_aligned_32, axis=0) \n",
    "        #print('expand ', im_expand.shape)\n",
    "        im_normalizada = (im_expand - np.min(im_expand)) / (np.max(im_expand) - np.min(im_expand))\n",
    "        #normalizando predice probabilidades!\n",
    "        \n",
    "        prediccion = model.predict(im_normalizada)\n",
    "        \n",
    "        pred = np.argmax(prediccion)\n",
    "        proba = prediccion[:,pred]\n",
    "        tag = tags[pred]\n",
    "\n",
    "        #print('PREDICCION ', prediccion)\n",
    "        #print('pred ',pred)\n",
    "        #print('prob ',proba)\n",
    "        #arreglar que no identifique a 2 personas con el mismo id!\n",
    "        \n",
    "        if proba > .5: # & reconoce al mismo id durante 2s\n",
    "            print('{}: {}'.format(tag, proba))\n",
    "            cv2.putText(frame, tag, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (cara.right(),cara.bottom()), (0,255,0), 3)\n",
    "        \n",
    "        for n in range(0,68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x,y), 3, (255,0,0))\n",
    "\n",
    "        cv2.imshow('Cara alineada', face_aligned)\n",
    "\n",
    "\n",
    "    cv2.imshow('Frame',frame)\n",
    "    \n",
    "    if key == ord ('q'):\n",
    "        seguir=False\n",
    "        \n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3\n",
    "\n",
    "Resultados con poca precision comparados con VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 188 images belonging to 8 classes.\n",
      "Found 42 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#redimensiono con default_size de InceptionV3, 299x299\n",
    "\n",
    "generador = ImageDataGenerator(validation_split=0.2,\n",
    "                               rescale=1./255,\n",
    "                               shear_range = 0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "\n",
    "training_generator = generador.flow_from_directory('/Users/andresmanzalini/Documents/Datasets',\n",
    "                                                   target_size = (299,299),\n",
    "                                                   batch_size=8,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='training')\n",
    "\n",
    "validation_generator = generador.flow_from_directory('/Users/andresmanzalini/Documents/Datasets',\n",
    "                                                     target_size = (299,299),\n",
    "                                                     batch_size=8,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, None, None, 3 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, None, 3 96          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 3 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, None, None, 3 9216        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, None, 3 96          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 3 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, None, None, 6 18432       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, None, 6 192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 6 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, None, None, 6 0           activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, None, 8 240         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 8 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, None, None, 1 138240      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, None, None, 1 576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 1 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, None, None, 1 0           activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, None, None, 6 192         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 6 0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, None, None, 9 55296       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, None, None, 4 144         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, None, None, 9 288         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 4 0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 9 0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, None, None, 1 0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, None, None, 6 76800       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, None, None, 9 82944       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, None, None, 6 192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, None, None, 6 192         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, None, None, 9 288         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, None, None, 3 96          conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 6 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, None, None, 6 0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 9 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 3 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_194[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, None, None, 6 192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, None, None, 6 0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, None, None, 9 55296       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, None, None, 4 144         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, None, None, 9 288         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 4 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, None, None, 9 0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, None, None, 6 76800       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, None, None, 9 82944       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, None, None, 6 192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, None, None, 6 192         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, None, None, 9 288         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, None, None, 6 192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 6 0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, None, None, 6 0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, None, None, 9 0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, None, None, 6 0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_201[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "                                                                 activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, None, None, 6 192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, None, None, 6 0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, None, None, 9 55296       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, None, None, 4 144         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, None, None, 9 288         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, None, None, 4 0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, None, None, 9 0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, None, None, 6 76800       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, None, None, 9 82944       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, None, None, 6 192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, None, None, 6 192         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, None, None, 9 288         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, None, None, 6 192         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, None, None, 6 0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, None, None, 6 0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, None, None, 9 0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, None, None, 6 0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_208[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, None, None, 6 192         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, None, None, 6 0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, None, None, 9 55296       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, None, None, 9 288         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, None, None, 9 0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, None, None, 9 82944       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, None, None, 3 1152        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, None, None, 9 288         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, None, None, 3 0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, None, None, 9 0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_215[0][0]             \n",
      "                                                                 activation_218[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, None, None, 1 384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, None, None, 1 0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, None, None, 1 114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, None, None, 1 384         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, None, None, 1 0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, None, None, 1 114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, None, None, 1 384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, None, None, 1 384         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, None, None, 1 0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, None, None, 1 0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, None, None, 1 114688      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, None, None, 1 114688      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, None, None, 1 384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, None, None, 1 384         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, None, None, 1 0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, None, None, 1 0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, None, None, 1 172032      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, None, None, 1 172032      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, None, None, 1 576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, None, None, 1 576         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, None, None, 1 576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, None, None, 1 576         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, None, None, 1 0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, None, None, 1 0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, None, None, 1 0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, None, None, 1 0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_219[0][0]             \n",
      "                                                                 activation_222[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "                                                                 activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, None, None, 1 480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, None, None, 1 0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, None, None, 1 179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, None, None, 1 480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, None, None, 1 0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, None, None, 1 179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, None, None, 1 480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, None, None, 1 480         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, None, None, 1 0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, None, None, 1 0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, None, None, 1 179200      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, None, None, 1 179200      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, None, None, 1 480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, None, None, 1 480         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, None, None, 1 0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, None, None, 1 0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, None, None, 1 215040      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, None, None, 1 215040      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, None, None, 1 576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, None, None, 1 576         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, None, None, 1 576         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, None, None, 1 576         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, None, None, 1 0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, None, None, 1 0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, None, None, 1 0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, None, None, 1 0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_229[0][0]             \n",
      "                                                                 activation_232[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "                                                                 activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, None, None, 1 480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, None, None, 1 0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, None, None, 1 179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, None, None, 1 480         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, None, None, 1 0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, None, None, 1 179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, None, None, 1 480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, None, None, 1 480         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, None, None, 1 0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, None, None, 1 0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, None, None, 1 179200      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, None, None, 1 179200      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, None, None, 1 480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, None, None, 1 480         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, None, None, 1 0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, None, None, 1 0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, None, None, 1 215040      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, None, None, 1 215040      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, None, None, 1 576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, None, None, 1 576         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, None, None, 1 576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, None, None, 1 576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, None, None, 1 0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, None, None, 1 0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, None, None, 1 0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, None, None, 1 0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_239[0][0]             \n",
      "                                                                 activation_242[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, None, None, 1 576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, None, None, 1 0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, None, None, 1 258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, None, None, 1 576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, None, None, 1 0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, None, None, 1 258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, None, None, 1 576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, None, None, 1 576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, None, None, 1 0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, None, None, 1 0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, None, None, 1 258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, None, None, 1 258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, None, None, 1 576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, None, None, 1 576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, None, None, 1 0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, None, None, 1 0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, None, None, 1 258048      activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, None, None, 1 258048      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, None, None, 1 576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, None, None, 1 576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, None, None, 1 576         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, None, None, 1 576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, None, None, 1 0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, None, None, 1 0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, None, None, 1 0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, None, None, 1 0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_249[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, None, None, 1 576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, None, None, 1 0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, None, None, 1 258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, None, None, 1 576         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, None, None, 1 0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, None, None, 1 258048      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, None, None, 1 576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, None, None, 1 576         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, None, None, 1 0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, None, None, 1 0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, None, None, 3 552960      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, None, None, 1 331776      activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, None, None, 3 960         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, None, None, 1 576         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, None, None, 3 0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, None, None, 1 0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_260[0][0]             \n",
      "                                                                 activation_264[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, None, None, 4 1344        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, None, None, 4 0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, None, None, 3 1548288     activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, None, None, 3 1152        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, None, None, 3 1152        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, None, None, 3 0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, None, None, 3 0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, None, None, 3 442368      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, None, None, 3 442368      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, None, None, 3 442368      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, None, None, 3 442368      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, None, None, 3 1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, None, None, 3 1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, None, None, 3 1152        conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, None, None, 3 1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, None, None, 3 960         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, None, None, 3 0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, None, None, 3 0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, None, None, 3 0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, None, None, 3 0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, None, None, 1 576         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, None, None, 3 0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_267[0][0]             \n",
      "                                                                 activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 7 0           activation_271[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, None, None, 1 0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_265[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, None, None, 4 1344        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, None, None, 4 0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, None, None, 3 1548288     activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, None, None, 3 1152        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, None, None, 3 1152        conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, None, None, 3 0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, None, None, 3 0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, None, None, 3 442368      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, None, None, 3 442368      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, None, None, 3 442368      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, None, None, 3 442368      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, None, None, 3 1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, None, None, 3 1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, None, None, 3 1152        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, None, None, 3 1152        conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, None, None, 3 960         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, None, None, 3 0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, None, None, 3 0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, None, None, 3 0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, None, None, 3 0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, None, None, 1 576         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, None, None, 3 0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_276[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 7 0           activation_280[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, None, None, 1 0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_274[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          262400      dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            2056        dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,165,416\n",
      "Trainable params: 24,130,984\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(cant_ids, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, None, None, 3 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, None, 3 96          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 3 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, None, None, 3 9216        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, None, 3 96          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 3 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, None, None, 6 18432       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, None, 6 192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 6 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, None, None, 6 0           activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, None, 8 240         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 8 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, None, None, 1 138240      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, None, None, 1 576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 1 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, None, None, 1 0           activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, None, None, 6 192         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 6 0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, None, None, 9 55296       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, None, None, 4 144         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, None, None, 9 288         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 4 0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 9 0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, None, None, 1 0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, None, None, 6 76800       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, None, None, 9 82944       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, None, None, 6 192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, None, None, 6 192         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, None, None, 9 288         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, None, None, 3 96          conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 6 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, None, None, 6 0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 9 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 3 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_194[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, None, None, 6 192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, None, None, 6 0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, None, None, 9 55296       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, None, None, 4 144         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, None, None, 9 288         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 4 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, None, None, 9 0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, None, None, 6 76800       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, None, None, 9 82944       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, None, None, 6 192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, None, None, 6 192         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, None, None, 9 288         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, None, None, 6 192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 6 0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, None, None, 6 0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, None, None, 9 0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, None, None, 6 0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_201[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "                                                                 activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, None, None, 6 192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, None, None, 6 0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, None, None, 9 55296       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, None, None, 4 144         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, None, None, 9 288         conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, None, None, 4 0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, None, None, 9 0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, None, None, 6 76800       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, None, None, 9 82944       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, None, None, 6 192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, None, None, 6 192         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, None, None, 9 288         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, None, None, 6 192         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, None, None, 6 0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, None, None, 6 0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, None, None, 9 0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, None, None, 6 0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_208[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "                                                                 activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, None, None, 6 192         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, None, None, 6 0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, None, None, 9 55296       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, None, None, 9 288         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, None, None, 9 0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, None, None, 9 82944       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, None, None, 3 1152        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, None, None, 9 288         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, None, None, 3 0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, None, None, 9 0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_215[0][0]             \n",
      "                                                                 activation_218[0][0]             \n",
      "                                                                 max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, None, None, 1 384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, None, None, 1 0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, None, None, 1 114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, None, None, 1 384         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, None, None, 1 0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, None, None, 1 114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, None, None, 1 384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, None, None, 1 384         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, None, None, 1 0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, None, None, 1 0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, None, None, 1 114688      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, None, None, 1 114688      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, None, None, 1 384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, None, None, 1 384         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, None, None, 1 0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, None, None, 1 0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, None, None, 1 172032      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, None, None, 1 172032      activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, None, None, 1 576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, None, None, 1 576         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, None, None, 1 576         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, None, None, 1 576         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, None, None, 1 0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, None, None, 1 0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, None, None, 1 0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, None, None, 1 0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_219[0][0]             \n",
      "                                                                 activation_222[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "                                                                 activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, None, None, 1 480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, None, None, 1 0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, None, None, 1 179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, None, None, 1 480         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, None, None, 1 0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, None, None, 1 179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, None, None, 1 480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, None, None, 1 480         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, None, None, 1 0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, None, None, 1 0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, None, None, 1 179200      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, None, None, 1 179200      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, None, None, 1 480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, None, None, 1 480         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, None, None, 1 0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, None, None, 1 0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, None, None, 1 215040      activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, None, None, 1 215040      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, None, None, 1 576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, None, None, 1 576         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, None, None, 1 576         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, None, None, 1 576         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, None, None, 1 0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, None, None, 1 0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, None, None, 1 0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, None, None, 1 0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_229[0][0]             \n",
      "                                                                 activation_232[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "                                                                 activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, None, None, 1 480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, None, None, 1 0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, None, None, 1 179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, None, None, 1 480         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, None, None, 1 0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, None, None, 1 179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, None, None, 1 480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, None, None, 1 480         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, None, None, 1 0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, None, None, 1 0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, None, None, 1 179200      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, None, None, 1 179200      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, None, None, 1 480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, None, None, 1 480         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, None, None, 1 0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, None, None, 1 0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, None, None, 1 215040      activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, None, None, 1 215040      activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, None, None, 1 576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, None, None, 1 576         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, None, None, 1 576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, None, None, 1 576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, None, None, 1 0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, None, None, 1 0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, None, None, 1 0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, None, None, 1 0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_239[0][0]             \n",
      "                                                                 activation_242[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, None, None, 1 576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, None, None, 1 0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, None, None, 1 258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, None, None, 1 576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, None, None, 1 0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, None, None, 1 258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, None, None, 1 576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, None, None, 1 576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, None, None, 1 0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, None, None, 1 0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, None, None, 1 258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, None, None, 1 258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, None, None, 1 576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, None, None, 1 576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, None, None, 1 0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, None, None, 1 0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, None, None, 1 258048      activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, None, None, 1 258048      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, None, None, 1 576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, None, None, 1 576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, None, None, 1 576         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, None, None, 1 576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, None, None, 1 0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, None, None, 1 0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, None, None, 1 0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, None, None, 1 0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_249[0][0]             \n",
      "                                                                 activation_252[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, None, None, 1 576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, None, None, 1 0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, None, None, 1 258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, None, None, 1 576         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, None, None, 1 0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, None, None, 1 258048      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, None, None, 1 576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, None, None, 1 576         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, None, None, 1 0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, None, None, 1 0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, None, None, 3 552960      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, None, None, 1 331776      activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, None, None, 3 960         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, None, None, 1 576         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, None, None, 3 0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, None, None, 1 0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_260[0][0]             \n",
      "                                                                 activation_264[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, None, None, 4 1344        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, None, None, 4 0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, None, None, 3 1548288     activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, None, None, 3 1152        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, None, None, 3 1152        conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, None, None, 3 0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, None, None, 3 0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, None, None, 3 442368      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, None, None, 3 442368      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, None, None, 3 442368      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, None, None, 3 442368      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, None, None, 3 1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, None, None, 3 1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, None, None, 3 1152        conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, None, None, 3 1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, None, None, 3 960         conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, None, None, 3 0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, None, None, 3 0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, None, None, 3 0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, None, None, 3 0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, None, None, 1 576         conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, None, None, 3 0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_267[0][0]             \n",
      "                                                                 activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 7 0           activation_271[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, None, None, 1 0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_265[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, None, None, 4 1344        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, None, None, 4 0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, None, None, 3 1548288     activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, None, None, 3 1152        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, None, None, 3 1152        conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, None, None, 3 0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, None, None, 3 0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, None, None, 3 442368      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, None, None, 3 442368      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, None, None, 3 442368      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, None, None, 3 442368      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, None, None, 3 1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, None, None, 3 1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, None, None, 3 1152        conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, None, None, 3 1152        conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, None, None, 3 960         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, None, None, 3 0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, None, None, 3 0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, None, None, 3 0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, None, None, 3 0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, None, None, 1 576         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, None, None, 3 0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_276[0][0]             \n",
      "                                                                 activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, None, 7 0           activation_280[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, None, None, 1 0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_274[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 256)          262400      dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            2056        dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,165,416\n",
      "Trainable params: 2,362,632\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 54s 2s/step - loss: 4.1093 - acc: 0.1979 - val_loss: 2.0328 - val_acc: 0.2857\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 47s 2s/step - loss: 1.7744 - acc: 0.3438 - val_loss: 2.3772 - val_acc: 0.2857\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 49s 2s/step - loss: 1.4705 - acc: 0.4737 - val_loss: 3.7888 - val_acc: 0.2857\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 47s 2s/step - loss: 1.2135 - acc: 0.6351 - val_loss: 2.4413 - val_acc: 0.2381\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 46s 2s/step - loss: 1.1573 - acc: 0.6147 - val_loss: 2.6610 - val_acc: 0.1190\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.9243 - acc: 0.7033 - val_loss: 2.8689 - val_acc: 0.3810\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 46s 2s/step - loss: 0.7973 - acc: 0.7291 - val_loss: 2.0043 - val_acc: 0.4286\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 46s 2s/step - loss: 0.8850 - acc: 0.6983 - val_loss: 6.1244 - val_acc: 0.1905\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 47s 2s/step - loss: 0.8113 - acc: 0.7298 - val_loss: 3.6442 - val_acc: 0.1905\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 48s 2s/step - loss: 0.6752 - acc: 0.7917 - val_loss: 3.0944 - val_acc: 0.4762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7941472282012305, 0.47619047619047616]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "h = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        epochs=50,\n",
    "                        steps_per_epoch=len(training_generator),\n",
    "                        validation_steps=len(validation_generator))\n",
    "\n",
    "\n",
    "model.evaluate_generator(generator=validation_generator,\n",
    "                         steps=len(validation_generator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_4\n",
      "1 conv2d_191\n",
      "2 batch_normalization_189\n",
      "3 activation_189\n",
      "4 conv2d_192\n",
      "5 batch_normalization_190\n",
      "6 activation_190\n",
      "7 conv2d_193\n",
      "8 batch_normalization_191\n",
      "9 activation_191\n",
      "10 max_pooling2d_11\n",
      "11 conv2d_194\n",
      "12 batch_normalization_192\n",
      "13 activation_192\n",
      "14 conv2d_195\n",
      "15 batch_normalization_193\n",
      "16 activation_193\n",
      "17 max_pooling2d_12\n",
      "18 conv2d_199\n",
      "19 batch_normalization_197\n",
      "20 activation_197\n",
      "21 conv2d_197\n",
      "22 conv2d_200\n",
      "23 batch_normalization_195\n",
      "24 batch_normalization_198\n",
      "25 activation_195\n",
      "26 activation_198\n",
      "27 average_pooling2d_19\n",
      "28 conv2d_196\n",
      "29 conv2d_198\n",
      "30 conv2d_201\n",
      "31 conv2d_202\n",
      "32 batch_normalization_194\n",
      "33 batch_normalization_196\n",
      "34 batch_normalization_199\n",
      "35 batch_normalization_200\n",
      "36 activation_194\n",
      "37 activation_196\n",
      "38 activation_199\n",
      "39 activation_200\n",
      "40 mixed0\n",
      "41 conv2d_206\n",
      "42 batch_normalization_204\n",
      "43 activation_204\n",
      "44 conv2d_204\n",
      "45 conv2d_207\n",
      "46 batch_normalization_202\n",
      "47 batch_normalization_205\n",
      "48 activation_202\n",
      "49 activation_205\n",
      "50 average_pooling2d_20\n",
      "51 conv2d_203\n",
      "52 conv2d_205\n",
      "53 conv2d_208\n",
      "54 conv2d_209\n",
      "55 batch_normalization_201\n",
      "56 batch_normalization_203\n",
      "57 batch_normalization_206\n",
      "58 batch_normalization_207\n",
      "59 activation_201\n",
      "60 activation_203\n",
      "61 activation_206\n",
      "62 activation_207\n",
      "63 mixed1\n",
      "64 conv2d_213\n",
      "65 batch_normalization_211\n",
      "66 activation_211\n",
      "67 conv2d_211\n",
      "68 conv2d_214\n",
      "69 batch_normalization_209\n",
      "70 batch_normalization_212\n",
      "71 activation_209\n",
      "72 activation_212\n",
      "73 average_pooling2d_21\n",
      "74 conv2d_210\n",
      "75 conv2d_212\n",
      "76 conv2d_215\n",
      "77 conv2d_216\n",
      "78 batch_normalization_208\n",
      "79 batch_normalization_210\n",
      "80 batch_normalization_213\n",
      "81 batch_normalization_214\n",
      "82 activation_208\n",
      "83 activation_210\n",
      "84 activation_213\n",
      "85 activation_214\n",
      "86 mixed2\n",
      "87 conv2d_218\n",
      "88 batch_normalization_216\n",
      "89 activation_216\n",
      "90 conv2d_219\n",
      "91 batch_normalization_217\n",
      "92 activation_217\n",
      "93 conv2d_217\n",
      "94 conv2d_220\n",
      "95 batch_normalization_215\n",
      "96 batch_normalization_218\n",
      "97 activation_215\n",
      "98 activation_218\n",
      "99 max_pooling2d_13\n",
      "100 mixed3\n",
      "101 conv2d_225\n",
      "102 batch_normalization_223\n",
      "103 activation_223\n",
      "104 conv2d_226\n",
      "105 batch_normalization_224\n",
      "106 activation_224\n",
      "107 conv2d_222\n",
      "108 conv2d_227\n",
      "109 batch_normalization_220\n",
      "110 batch_normalization_225\n",
      "111 activation_220\n",
      "112 activation_225\n",
      "113 conv2d_223\n",
      "114 conv2d_228\n",
      "115 batch_normalization_221\n",
      "116 batch_normalization_226\n",
      "117 activation_221\n",
      "118 activation_226\n",
      "119 average_pooling2d_22\n",
      "120 conv2d_221\n",
      "121 conv2d_224\n",
      "122 conv2d_229\n",
      "123 conv2d_230\n",
      "124 batch_normalization_219\n",
      "125 batch_normalization_222\n",
      "126 batch_normalization_227\n",
      "127 batch_normalization_228\n",
      "128 activation_219\n",
      "129 activation_222\n",
      "130 activation_227\n",
      "131 activation_228\n",
      "132 mixed4\n",
      "133 conv2d_235\n",
      "134 batch_normalization_233\n",
      "135 activation_233\n",
      "136 conv2d_236\n",
      "137 batch_normalization_234\n",
      "138 activation_234\n",
      "139 conv2d_232\n",
      "140 conv2d_237\n",
      "141 batch_normalization_230\n",
      "142 batch_normalization_235\n",
      "143 activation_230\n",
      "144 activation_235\n",
      "145 conv2d_233\n",
      "146 conv2d_238\n",
      "147 batch_normalization_231\n",
      "148 batch_normalization_236\n",
      "149 activation_231\n",
      "150 activation_236\n",
      "151 average_pooling2d_23\n",
      "152 conv2d_231\n",
      "153 conv2d_234\n",
      "154 conv2d_239\n",
      "155 conv2d_240\n",
      "156 batch_normalization_229\n",
      "157 batch_normalization_232\n",
      "158 batch_normalization_237\n",
      "159 batch_normalization_238\n",
      "160 activation_229\n",
      "161 activation_232\n",
      "162 activation_237\n",
      "163 activation_238\n",
      "164 mixed5\n",
      "165 conv2d_245\n",
      "166 batch_normalization_243\n",
      "167 activation_243\n",
      "168 conv2d_246\n",
      "169 batch_normalization_244\n",
      "170 activation_244\n",
      "171 conv2d_242\n",
      "172 conv2d_247\n",
      "173 batch_normalization_240\n",
      "174 batch_normalization_245\n",
      "175 activation_240\n",
      "176 activation_245\n",
      "177 conv2d_243\n",
      "178 conv2d_248\n",
      "179 batch_normalization_241\n",
      "180 batch_normalization_246\n",
      "181 activation_241\n",
      "182 activation_246\n",
      "183 average_pooling2d_24\n",
      "184 conv2d_241\n",
      "185 conv2d_244\n",
      "186 conv2d_249\n",
      "187 conv2d_250\n",
      "188 batch_normalization_239\n",
      "189 batch_normalization_242\n",
      "190 batch_normalization_247\n",
      "191 batch_normalization_248\n",
      "192 activation_239\n",
      "193 activation_242\n",
      "194 activation_247\n",
      "195 activation_248\n",
      "196 mixed6\n",
      "197 conv2d_255\n",
      "198 batch_normalization_253\n",
      "199 activation_253\n",
      "200 conv2d_256\n",
      "201 batch_normalization_254\n",
      "202 activation_254\n",
      "203 conv2d_252\n",
      "204 conv2d_257\n",
      "205 batch_normalization_250\n",
      "206 batch_normalization_255\n",
      "207 activation_250\n",
      "208 activation_255\n",
      "209 conv2d_253\n",
      "210 conv2d_258\n",
      "211 batch_normalization_251\n",
      "212 batch_normalization_256\n",
      "213 activation_251\n",
      "214 activation_256\n",
      "215 average_pooling2d_25\n",
      "216 conv2d_251\n",
      "217 conv2d_254\n",
      "218 conv2d_259\n",
      "219 conv2d_260\n",
      "220 batch_normalization_249\n",
      "221 batch_normalization_252\n",
      "222 batch_normalization_257\n",
      "223 batch_normalization_258\n",
      "224 activation_249\n",
      "225 activation_252\n",
      "226 activation_257\n",
      "227 activation_258\n",
      "228 mixed7\n",
      "229 conv2d_263\n",
      "230 batch_normalization_261\n",
      "231 activation_261\n",
      "232 conv2d_264\n",
      "233 batch_normalization_262\n",
      "234 activation_262\n",
      "235 conv2d_261\n",
      "236 conv2d_265\n",
      "237 batch_normalization_259\n",
      "238 batch_normalization_263\n",
      "239 activation_259\n",
      "240 activation_263\n",
      "241 conv2d_262\n",
      "242 conv2d_266\n",
      "243 batch_normalization_260\n",
      "244 batch_normalization_264\n",
      "245 activation_260\n",
      "246 activation_264\n",
      "247 max_pooling2d_14\n",
      "248 mixed8\n",
      "249 conv2d_271\n",
      "250 batch_normalization_269\n",
      "251 activation_269\n",
      "252 conv2d_268\n",
      "253 conv2d_272\n",
      "254 batch_normalization_266\n",
      "255 batch_normalization_270\n",
      "256 activation_266\n",
      "257 activation_270\n",
      "258 conv2d_269\n",
      "259 conv2d_270\n",
      "260 conv2d_273\n",
      "261 conv2d_274\n",
      "262 average_pooling2d_26\n",
      "263 conv2d_267\n",
      "264 batch_normalization_267\n",
      "265 batch_normalization_268\n",
      "266 batch_normalization_271\n",
      "267 batch_normalization_272\n",
      "268 conv2d_275\n",
      "269 batch_normalization_265\n",
      "270 activation_267\n",
      "271 activation_268\n",
      "272 activation_271\n",
      "273 activation_272\n",
      "274 batch_normalization_273\n",
      "275 activation_265\n",
      "276 mixed9_0\n",
      "277 concatenate_5\n",
      "278 activation_273\n",
      "279 mixed9\n",
      "280 conv2d_280\n",
      "281 batch_normalization_278\n",
      "282 activation_278\n",
      "283 conv2d_277\n",
      "284 conv2d_281\n",
      "285 batch_normalization_275\n",
      "286 batch_normalization_279\n",
      "287 activation_275\n",
      "288 activation_279\n",
      "289 conv2d_278\n",
      "290 conv2d_279\n",
      "291 conv2d_282\n",
      "292 conv2d_283\n",
      "293 average_pooling2d_27\n",
      "294 conv2d_276\n",
      "295 batch_normalization_276\n",
      "296 batch_normalization_277\n",
      "297 batch_normalization_280\n",
      "298 batch_normalization_281\n",
      "299 conv2d_284\n",
      "300 batch_normalization_274\n",
      "301 activation_276\n",
      "302 activation_277\n",
      "303 activation_280\n",
      "304 activation_281\n",
      "305 batch_normalization_282\n",
      "306 activation_274\n",
      "307 mixed9_1\n",
      "308 concatenate_6\n",
      "309 activation_282\n",
      "310 mixed10\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 69s 3s/step - loss: 0.4283 - acc: 0.8593 - val_loss: 2.6185 - val_acc: 0.3571\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 59s 2s/step - loss: 0.2577 - acc: 0.9218 - val_loss: 2.1542 - val_acc: 0.4286\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 62s 3s/step - loss: 0.1952 - acc: 0.9429 - val_loss: 1.7679 - val_acc: 0.5476\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 61s 3s/step - loss: 0.2123 - acc: 0.9327 - val_loss: 2.1589 - val_acc: 0.4524\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 55s 2s/step - loss: 0.2246 - acc: 0.9322 - val_loss: 2.1510 - val_acc: 0.4524\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 57s 2s/step - loss: 0.1835 - acc: 0.9479 - val_loss: 2.1237 - val_acc: 0.4286\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.0847 - acc: 0.9794 - val_loss: 1.8881 - val_acc: 0.5714\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 61s 3s/step - loss: 0.1191 - acc: 0.9739 - val_loss: 2.3623 - val_acc: 0.4524\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 58s 2s/step - loss: 0.0773 - acc: 0.9794 - val_loss: 1.8319 - val_acc: 0.5238\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.1596 - acc: 0.9739 - val_loss: 1.4176 - val_acc: 0.5238\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.1294 - acc: 0.9585 - val_loss: 1.8061 - val_acc: 0.5476\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 56s 2s/step - loss: 0.1041 - acc: 0.9791 - val_loss: 2.6439 - val_acc: 0.4762\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 58s 2s/step - loss: 0.0414 - acc: 0.9896 - val_loss: 1.7927 - val_acc: 0.5476\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.0397 - acc: 0.9948 - val_loss: 2.1188 - val_acc: 0.4762\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0744 - acc: 0.9739 - val_loss: 1.9828 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0516 - acc: 0.9948 - val_loss: 2.2197 - val_acc: 0.5238\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0516 - acc: 0.9896 - val_loss: 2.1553 - val_acc: 0.5238\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0371 - acc: 0.9948 - val_loss: 2.1098 - val_acc: 0.4524\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0694 - acc: 0.9739 - val_loss: 2.3003 - val_acc: 0.4286\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0639 - acc: 0.9687 - val_loss: 1.8372 - val_acc: 0.4286\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.0363 - acc: 0.9948 - val_loss: 2.0138 - val_acc: 0.5714\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 54s 2s/step - loss: 0.0314 - acc: 0.9948 - val_loss: 1.7661 - val_acc: 0.5476\n",
      "Epoch 23/50\n",
      " 4/24 [====>.........................] - ETA: 40s - loss: 0.0222 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-bc720e9f29d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                         validation_steps=len(validation_generator))\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m model.evaluate_generator(generator=validation_generator,\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#numero de capas para cortar al hacer fine tuning\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False #congelo primeras 249 capas\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True    #descongelo el resto\n",
    "\n",
    "# recompilar con SGD\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "h = model.fit_generator(generator=training_generator,\n",
    "                        validation_data=validation_generator,\n",
    "                        epochs=50,\n",
    "                        steps_per_epoch=len(training_generator),\n",
    "                        validation_steps=len(validation_generator))\n",
    "\n",
    "model.evaluate_generator(generator=validation_generator,\n",
    "                         steps=len(validation_generator))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTADOS\n",
    "\n",
    "#mas complejo computacionalmente\n",
    "#entrenando todas las capas:\n",
    "    #de entrada mucho valor de perdida, se va acomodando\n",
    "    #1.3 de perdida, 0.43 de precision\n",
    "\n",
    "#con fine-tuning, congelando la estructura de la arquitectura y entrenando solo las ultimas capas\n",
    "#UPAAAAA. esto no es coca papi. \n",
    "#es pepsi -_-, \n",
    "#con 5 epochs  =>   no sirve para reconocer caras. loss=1.03, acc=0.51\n",
    "#con 10 epochs =>   una bazo... loss=1.5, acc=0.48 \n",
    "                    #amaga con que arranca y es lo mejor, pero la queda siempre, en todos los epochs. \n",
    "                    #es el vivi hecho modelo de IA\n",
    "#con 20 epochs =>   lo mismo\n",
    "\n",
    "#no distingue bien los rostros, por lo que no puede clasificar con precision\n",
    "\n",
    "# creo yo que es porque al tener tantas pequenas capas, apunta mas a los detalles \n",
    "# que a un conjunto de puntos mas complejos, como los que representan una cara\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo base VGG16 es el mejor para la implementacion del proyecto, ya que extrae carecteristicas mas generales de las imagenes. En cambio el modelo InceptionV3 tiene muchas mas pequeñas capas y enfoca los detalles por sobre el objeto general.\n",
    "\n",
    "Las métricas iniciales del VGG16 parecen consistentes, pero es sensible al underfitting.\n",
    "\n",
    "Para eso una alternativa es aplicar fine tuning agregando al final 2 capas convolucionales para achicar el tensor y 2 fully conected para clasificar los rostros en el arreglo plano. \n",
    "\n",
    "A pesar de estas mejoras no clasifica del todo bien porque, en esta implementacion, las imagenes de prueba del dataset son pocas (considerando la carga manual con detectarProcesar_cara.py) \n",
    "\n",
    "Lo mas llamativo es la normalizacion establecida por keras_vggFace. No se que hace con la imagen de la webcam ni en que la transforma. Mejora la precision? Mmm\n",
    "\n",
    "Para hacer efectivo un dataset chico hay que sacar el maximo provecho de la informacion: redes neuronales siamesas o facenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En proceso..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes siamesas \n",
    "\n",
    "\n",
    "One-shot learning\n",
    "\n",
    "Comparo imagenes del mismo subconjunto y calculo el triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras import Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#uso de triplet loss.\n",
    "#compara de a 3 medidas a la vez, y se va aproximando al positivo a medida que entrena el algoritmo\n",
    "\n",
    "vgg = VGG16(input_shape=(default_size), weights='imagenet', include_top=False)#, classes=3)\n",
    "\n",
    "#vgg.summary()\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flatten()(vgg.output) #aplano vgg con sus respectivos pesos definidos en imagenet\n",
    "\n",
    "x = BatchNormalization()(f)\n",
    "\n",
    "d = Dropout(0.2)(x)\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01))\n",
    "out = Dense(4, activation='softmax')(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 25088)             100352    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 100356    \n",
      "=================================================================\n",
      "Total params: 14,915,396\n",
      "Trainable params: 150,532\n",
      "Non-trainable params: 14,764,864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andresmanzalini/miniconda3/envs/envDeepLearning/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=vgg.input, outputs=out) #input model o vgg?\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'vgg16_4/block5_pool/MaxPool:0' shape=(?, 7, 7, 512) dtype=float32>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seq_model = tf.keras.Sequential(vgg)\n",
    "\n",
    "left_input = Input(shape=default_size)\n",
    "right_input = Input(shape=default_size)\n",
    "\n",
    "#model = Sequential()\n",
    "#left_output = model(left_input)\n",
    "right_output = vgg(right_input)\n",
    "left_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_euclid = Lambda(lambda tensors : K.abs( tensors[0] - tensors[1] ))([left_output , right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = Dense(1 , activation='sigmoid')(distance_euclid)\n",
    "\n",
    "#model = Model(input=vgg.input, outputs=out) #input model o vgg?\n",
    "\n",
    "model = Model([left_input,right_input], outputs)\n",
    "model = Model(inputs=[left_input, right_input], outputs=outs)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 7, 7, 512)    14714688    input_32[0][0]                   \n",
      "                                                                 input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 7, 7, 512)    0           vgg16[1][0]                      \n",
      "                                                                 vgg16[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 7, 7, 1)      513         lambda_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,715,201\n",
      "Trainable params: 513\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articulos sobre redes neuronales siamesas\n",
    "\n",
    "# https://medium.com/predict/face-recognition-from-scratch-using-siamese-networks-and-tensorflow-df03e32f8cd0\n",
    "\n",
    "# https://www.codeproject.com/Articles/1253224/Keras-Implementation-of-Siamese-like-Networks\n",
    "\n",
    "# https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1503.03832.pdf\n",
    "\n",
    "# https://spanish.agatetepe.com.br/hacer-su-propio-sistema-de-reconocimiento-de-rostros/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el uso de vgg16 requiere la mencion del sgte paper \n",
    "# https://arxiv.org/abs/1409.1556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riesgos psicologicos de la programacion persuasiva con Redes Neuronales orientadas a deteccion de emociones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es para los que le gusta flasharla..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La combinacion de varios factores, como las mejoras tecnologicas en software y hardware, mas los avances en IA y la capacidad de manipulacion, permiten en el peor escenario, imaginar modelos de Deep Learning trabajando en conjunto y junto a la correcta sincronizacion de agentes inteligentes puede llevar a un desbalance psicologico/social.\n",
    "\n",
    "\n",
    "Supongamos el super modelo llamado Modelo Persuasivo de Emociones(MPE), cuyo algoritmo principal consiste en detectar emociones y manejarlas con eventos desencadenantes.\n",
    "Y los agentes inteligentes Agente Detector de Emociones y Agente de Feedback \n",
    "\n",
    "MPE en fase de aprendizaje, cada vez que se activa el Agente Detector de Emociones se revisan los eventos del sistema que desencadenaron esa reaccion. Puede ser un msj, un video, una cancion, un recordatorio, etc.\n",
    "\n",
    "Cuando hay informacion suficiente sobre el sujeto(el usuario), el algoritmo persuasivo detecta que, por ejemplo, estás triste. Ese evento lo relaciona con las cosas que te hacen feliz (BD relacionada a 'eventos desencadenantes de emocion', lo que contrarresta la tristeza, es decir la felicidad).\n",
    "\n",
    "A su vez, existe otro agente, el de Feedback, que analiza la reaccion global a cierto evento desencadenado por el agente persuasivo. Esto sirve para generar un feedback entre las emociones del usuario y las recomedaciones del sistema, mejorando el nivel de precision de los eventos sugeridos.\n",
    "\n",
    "Cuando este modelo obtenga resultados predecibles, va a haber encontrado el patron de comportamiento de la persona.\n",
    "Por lo tanto va a tener control la maquina por sobre el usuario.\n",
    "\n",
    "La maquina? o los que manejan esa maquina?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
